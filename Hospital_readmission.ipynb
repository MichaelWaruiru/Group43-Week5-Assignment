{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfeIatagqPZP0jpJTbJAbR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGaTeNjcxBEI",
        "outputId": "607568df-5bb8-4cd0-a9c3-266b6771cafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validated Accuracy: 0.632 ± 0.002\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1376  444]\n",
            " [ 786  686]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.76      0.69      1820\n",
            "           1       0.61      0.47      0.53      1472\n",
            "\n",
            "    accuracy                           0.63      3292\n",
            "   macro avg       0.62      0.61      0.61      3292\n",
            "weighted avg       0.62      0.63      0.62      3292\n",
            "\n",
            "Precision: 0.607\n",
            "Recall: 0.466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['readmission_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
        "import joblib\n",
        "\n",
        "# 2. Load Dataset\n",
        "df = pd.read_csv(\"readmission_data.csv\")  # Replace with your dataset path\n",
        "\n",
        "# 3. Define Target and Features\n",
        "df['readmitted'] = df['readmitted'].map({'Yes': 1, 'No': 0})\n",
        "X = df.drop('readmitted', axis=1)\n",
        "y = df['readmitted']\n",
        "\n",
        "# 4. Identify Feature Types by inspecting DataFrame columns\n",
        "numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Remove 'hospital_stay', 'patient_visits', 'num_diagnosis' from numerical as they should be categorical\n",
        "numerical_cols.remove('hospital_stay')\n",
        "numerical_cols.remove('patient_visits')\n",
        "numerical_cols.remove('num_diagnosis')\n",
        "\n",
        "\n",
        "# Add 'hospital_stay', 'patient_visits', 'num_diagnosis' to categorical\n",
        "categorical_cols.extend(['hospital_stay', 'patient_visits', 'num_diagnosis'])\n",
        "\n",
        "\n",
        "# 5. Preprocessing Pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "])\n",
        "\n",
        "# 6. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 7. Build Pipeline with Random Forest\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
        "])\n",
        "\n",
        "# 8. Cross-Validation for Overfitting Mitigation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "print(f\"Cross-validated Accuracy: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
        "\n",
        "# 9. Train Final Model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 10. Evaluate Model\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(f\"Precision: {precision_score(y_test, y_pred):.3f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred):.3f}\")\n",
        "\n",
        "# 11. Save Model for Deployment\n",
        "joblib.dump(pipeline, \"readmission_model.pkl\")"
      ]
    }
  ]
}